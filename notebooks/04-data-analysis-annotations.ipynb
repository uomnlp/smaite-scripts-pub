{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# @formatter:off\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "# @formatter:on\n",
    "import os\n",
    "\n",
    "os.chdir('../')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "## adjust this accordingly\n",
    "#@formatter:off\n",
    "files = !ls data/processed/*.jsonl\n",
    "#@formatter:on\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handystuff.loaders import load_jsonl\n",
    "data = []\n",
    "for f in files:\n",
    "    data.extend(load_jsonl(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatgpt_answers = load_jsonl('chatgpt0-2621.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(data) == len(chatgpt_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary = ['contra-article_1', 'contra-self_1', 'convince_1', 'new_1', 'verdict_1', 'simplified_verdict_1']\n",
    "ordinal = ['rate_1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordinal_scale_mapping = {\n",
    "    'false': 'false',\n",
    "    'true': 'true',\n",
    "    'satire': 'false',\n",
    "    'unk': 'half',\n",
    "    'half': 'half',\n",
    "    'hardly': 'half',\n",
    "    'almost': 'half',\n",
    "    'false': 'false',\n",
    "    -1: -1,\n",
    "    False: 'false',\n",
    "    True: 'true',\n",
    "    'inbetween': 'half',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simplified_ordinal_scale_mapping = {\n",
    "    'false': 'false',\n",
    "    'true': 'true',\n",
    "    'satire': 'false',\n",
    "    'unk': 'inbetween',\n",
    "    'half': 'inbetween',\n",
    "    'hardly': 'inbetween',\n",
    "    'almost': 'inbetween',\n",
    "    -1: -1,\n",
    "    False: 'false',\n",
    "    True: 'true',\n",
    "    'inbetween': 'inbetween',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(a['verdict_1'] for d in data for a in d['answers']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, List\n",
    "\n",
    "\n",
    "def how_many_equal(values: List[Any]):\n",
    "    max_agreements = max(sum(k == values[i] for j, k in enumerate(values) if i != j) + 1 for i in range(len(values)))\n",
    "    return max_agreements if max_agreements > 1 else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "failed = 0\n",
    "for chatgpt_answer, d in zip(chatgpt_answers, data):\n",
    "    try:\n",
    "        answer = json.loads(chatgpt_answer[:chatgpt_answer.index('}')+1])\n",
    "    except:\n",
    "        failed += 1\n",
    "        print(chatgpt_answer)\n",
    "        continue\n",
    "    answer = {f\"{k}_1\":v for k,v in answer.items()}\n",
    "    #answer['verdict'] = simplified_ordinal_scale_mapping[answer['verdict']]\n",
    "    answer['worker'] = 'CHATGPT'\n",
    "    d['answers'].append(answer)\n",
    "print(failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    for a in d['answers']:\n",
    "        a['simplified_verdict_1'] = ordinal_scale_mapping[a['verdict_1']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def calculate_data_agreement(data, key_suffix=''):\n",
    "    for d in tqdm(data):\n",
    "        d[f'agreements{key_suffix}'] = dict()\n",
    "        for answers in zip(*[a.items() for a in d['answers']]):\n",
    "            keys, values = zip(*answers)\n",
    "            values = [v for v in values if v != -1]\n",
    "            k = f\"{keys[0]}{key_suffix}\"\n",
    "            if k in ordinal:\n",
    "                d[k] = sum(values)/len(values)\n",
    "            elif k in binary:\n",
    "                if k == 'verdict_1':\n",
    "                    agreement = how_many_equal([ordinal_scale_mapping[v] for v in values])\n",
    "                else:\n",
    "                    agreement = how_many_equal(values)\n",
    "                d['agreements'][k] = agreement/len(values)\n",
    "                d[k] = max(values, key=values.count) if agreement > 0.5 else 'NO_AGREEMENT'\n",
    "calculate_data_agreement(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1025]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in ['contra-article_1', 'contra-self_1', 'verdict_1', 'convince_1', 'new_1', 'simplified_verdict_1']:\n",
    "    percent_perfect_agreement = sum(d['agreements'][k] == 1.0 for d in data)/len(data)\n",
    "    print(f\"{k} perfect agreement: {percent_perfect_agreement:.2f}\")\n",
    "print('----'*20)\n",
    "for k in ['contra-article_1', 'contra-self_1', 'verdict_1', 'convince_1', 'new_1', 'simplified_verdict_1']:\n",
    "    percent_at_least_some_agreement = sum(d['agreements'][k] > 0.5 for d in data)/len(data)\n",
    "    print(f\"{k} some agreement: {percent_at_least_some_agreement:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "keys = binary + ordinal\n",
    "def get_agreement_per_author(data):\n",
    "    per_key = {k: defaultdict(list) for k in keys}\n",
    "    binary_only = defaultdict(list)\n",
    "    overall = defaultdict(list)\n",
    "    for d in tqdm(data):\n",
    "        for a in d['answers']:\n",
    "            worker = a['worker']\n",
    "            for k in keys:\n",
    "                answer = a[k]\n",
    "                other_answers = [oa[k] for oa in d['answers'] if oa['worker'] != worker and oa[k] != -1]\n",
    "                if k == 'verdict_1':\n",
    "                    answer = ordinal_scale_mapping[answer]\n",
    "                    other_answers = [ordinal_scale_mapping[a] for a in other_answers]\n",
    "                # print(d['answers'])\n",
    "                # print(a)\n",
    "                # print(k)\n",
    "                # print(answer)\n",
    "                # print(other_answers)\n",
    "                # print(int(any(answer == oa for oa in other_answers)))\n",
    "                if answer != -1:\n",
    "                    score = any(answer == oa for oa in other_answers)\n",
    "                    per_key[k][worker].append(score)\n",
    "                    overall[worker].append(score)\n",
    "                    if k in binary and k != 'verdict_1' and k!='simplified_verdict_1':\n",
    "                        binary_only[worker].append(score)\n",
    "                    \n",
    "    return per_key, overall, binary_only\n",
    "per_key, overall, binary_only = get_agreement_per_author(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_percentage = {worker: sum(v)/len(v) for worker, v in overall.items()}\n",
    "binary_percentage = {worker: sum(v)/len(v) for worker, v in binary_only.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "by_key_percentage = {key: {worker: sum(v)/len(v) for worker, v in value.items()} for key, value in per_key.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, v in by_key_percentage.items():\n",
    "    print(k)\n",
    "    print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(overall_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k, value in by_key_percentage.items():\n",
    "    print(k)\n",
    "    for k,v in sorted(value.items(), key=lambda x: x[1], reverse=True):\n",
    "        print(f'{k}: {v:.2f}')\n",
    "print('overall')\n",
    "for k,v in sorted(overall_percentage.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f'{k}: {v:.2f}')\n",
    "print('binary only')\n",
    "for k,v in sorted(binary_percentage.items(), key=lambda x: x[1], reverse=True):\n",
    "    print(f'{k}: {v:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0]['answers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_data_agreement_reliability(data, reliability_dict, key_suffix='', min_reliability=0.5, by_key=False):\n",
    "    key_suffix = key_suffix or f'@{min_reliability}{\"_bk\" if by_key else \"\"}'\n",
    "    for d in tqdm(data):\n",
    "        d[f'agreements{key_suffix}'] = dict()\n",
    "        all_answers = [item for item in zip(*[a.items() for a in d['answers']]) if item[0][0] != 'worker']\n",
    "        workers = [a['worker'] for a in d['answers']]\n",
    "        #print(list(all_answers))\n",
    "        for answers in all_answers:\n",
    "            # print(d['answers'])\n",
    "            keys, values = zip(*answers)\n",
    "            # print(keys)\n",
    "            # print(values)\n",
    "            # print(workers)\n",
    "            original_k = keys[0]\n",
    "            k = f\"{keys[0]}{key_suffix}\"\n",
    "            if by_key:\n",
    "                values = [v for v,w in zip(values, workers) if v != -1 and reliability_dict[original_k][w] >= min_reliability]\n",
    "            else:\n",
    "                values = [v for v,w in zip(values, workers) if v != -1 and reliability_dict[w] >= min_reliability]\n",
    "            if values:                \n",
    "                #print(k)\n",
    "                if original_k in ordinal:\n",
    "                    d[k] = sum(values)/len(values)\n",
    "                elif original_k in binary:\n",
    "                    if original_k == 'verdict_1':\n",
    "                        agreement = how_many_equal([ordinal_scale_mapping[v] for v in values])\n",
    "                    else:\n",
    "                        agreement = how_many_equal(values)\n",
    "                    d[f'agreements{key_suffix}'][k] = agreement/len(values)\n",
    "                    #print(k)\n",
    "                    d[k] = max(values, key=values.count) if agreement > 0.5 else 'NO_AGREEMENT'\n",
    "            else:\n",
    "                d[k] = None\n",
    "calculate_data_agreement_reliability(data, overall_percentage, min_reliability=0.5, by_key=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_data_agreement_reliability(data, by_key_percentage, min_reliability=0.5, by_key=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_data_agreement_reliability(data, overall_percentage, min_reliability=0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_data_agreement_reliability(data, by_key_percentage, min_reliability=0.75, by_key=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_data_agreement_reliability(data, overall_percentage, min_reliability=0.69, by_key=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "calculate_data_agreement_reliability(data, by_key_percentage, min_reliability=0.69, by_key=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in 'simplified_', '':\n",
    "    for k in ('0.5', '0.5_bk', '0.69', '0.69_bk', '0.75', '0.75_bk'):\n",
    "        for d in data:\n",
    "            d[f'{p}plausible@{k}'] = True if d[f'{p}verdict_1@{k}'] != 'NO_AGREEMENT' else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in data:\n",
    "    chatgpt_answer = next((a for a in d['answers'] if a['worker'] == 'CHATGPT'), None)\n",
    "    for k in 'contra-article_1', 'contra-self_1', 'rate_1', 'verdict_1', 'convince_1', 'new_1', 'simplified_verdict_1':\n",
    "        d[f\"{k}_chatgpt\"] = chatgpt_answer[k] if chatgpt_answer else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_data_agreement_reliability_excluding(data, reliability_dict, key_suffix='', min_reliability=0.5, by_key=False, excluding=None):\n",
    "    excluding = excluding or set()\n",
    "    key_suffix = key_suffix or f'@{min_reliability}{\"_bk\" if by_key else \"\"}{\"excluding\" if excluding else None}'\n",
    "    for d in tqdm(data):\n",
    "        d[f'agreements{key_suffix}'] = dict()\n",
    "        all_answers = [item for item in zip(*[a.items() for a in d['answers']]) if item[0][0] != 'worker']\n",
    "        workers = [a['worker'] for a in d['answers']]\n",
    "        #print(list(all_answers))\n",
    "        for answers in all_answers:\n",
    "            # print(d['answers'])\n",
    "            keys, values = zip(*answers)\n",
    "            # print(keys)\n",
    "            # print(values)\n",
    "            # print(workers)\n",
    "            original_k = keys[0]\n",
    "            k = f\"{keys[0]}{key_suffix}\"\n",
    "            if by_key:\n",
    "                values = [v for v,w in zip(values, workers) if v != -1 and reliability_dict[original_k][w] >= min_reliability and w not in excluding]\n",
    "            else:\n",
    "                values = [v for v,w in zip(values, workers) if v != -1 and reliability_dict[w] >= min_reliability and w not in excluding]\n",
    "            if values:                \n",
    "                #print(k)\n",
    "                if original_k in ordinal:\n",
    "                    d[k] = sum(values)/len(values)\n",
    "                elif original_k in binary:\n",
    "                    if original_k == 'verdict_1':\n",
    "                        agreement = how_many_equal([ordinal_scale_mapping[v] for v in values])\n",
    "                    else:\n",
    "                        agreement = how_many_equal(values)\n",
    "                    d[f'agreements{key_suffix}'][k] = agreement/len(values)\n",
    "                    #print(k)\n",
    "                    d[k] = max(values, key=values.count) if agreement > 0.5 else 'NO_AGREEMENT'\n",
    "            else:\n",
    "                d[k] = None\n",
    "calculate_data_agreement_reliability_excluding(data, by_key_percentage, min_reliability=0.75, by_key=True, excluding={\"CHATGPT\"})\n",
    "calculate_data_agreement_reliability_excluding(data, overall_percentage, min_reliability=0.75, by_key=False, excluding={\"CHATGPT\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in 'contra-article_1', 'contra-self_1', 'rate_1', 'verdict_1', 'convince_1', 'new_1', 'plausible', 'simplified_verdict_1', 'simplified_plausible': \n",
    "    for ts in [None, 0.5, 0.69, 0.75]:\n",
    "        for bk in ['','_bk']:\n",
    "            for ex in ['', 'excluding']:\n",
    "                full_key = f\"{k}@{ts}{bk}{ex if ts == 0.75 else ''}\" if ts else k\n",
    "                label_dict = defaultdict(int)\n",
    "                for d in data:\n",
    "                    if full_key not in d:\n",
    "                        label_dict[None] += 1\n",
    "                    else:\n",
    "                        label_dict[d[full_key]] += 1\n",
    "                print(full_key, dict(label_dict))\n",
    "for k in 'contra-article_1', 'contra-self_1', 'rate_1', 'verdict_1', 'convince_1', 'new_1', 'simplified_verdict_1':\n",
    "    full_key = f\"{k}_chatgpt\"\n",
    "    label_dict = defaultdict(int)\n",
    "    for d in data:\n",
    "        if full_key not in d:\n",
    "            label_dict[None] += 1\n",
    "        else:\n",
    "            label_dict[d[full_key]] += 1\n",
    "    print(full_key, dict(label_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[1234]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from handystuff.loaders import write_jsonl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def we_need(k):\n",
    "    return k in ('claim', 'verdict', 'sources', 'text') or any(k.startswith(p) for p in ('contra', 'verdict', 'convince', 'new', 'simplified_verdict', 'rate', 'plausible', 'simplified_plausible'))\n",
    "def parse(v, k):\n",
    "    if isinstance(v, list):\n",
    "        return '\\n'.join(lv for lv in v)\n",
    "    if isinstance(v, float):\n",
    "        return v\n",
    "    if k.startswith('rate') and v is None:\n",
    "        return 0\n",
    "    else:\n",
    "        return str(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parsed_data = [{k:parse(v,k) for k,v in d.items() if we_need(k)} for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_jsonl(parsed_data, 'data-main-no-answers.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(pd['rate_1@0.69_bk'] for pd in parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum((pd['rate_1@0.75']-1)/4 for pd in parsed_data)/len(parsed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "print(mean_squared_error([0.7022128958412811]*len(parsed_data), [(pd['rate_1@0.75']-1)/4 for pd in parsed_data]))\n",
    "print(mean_absolute_error([0.7022128958412811]*len(parsed_data), [(pd['rate_1@0.75']-1)/4 for pd in parsed_data]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('smaite')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "8e59854198b62e77d92da15d0c036c042ba0ed0a9b0aaffcd75c388e7e8858f6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
